{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vvRwitMiMRRk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "MM2Tt9T8M7Hj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "ODorlc7lM81c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USO-J_EOM_Y5",
        "outputId": "0d4851a5-cf6a-40fd-e213-142f2f5b0961"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris.target_names)    # These are target names in which we have to classify our test data, after training the model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPC8f3I4NCB7",
        "outputId": "07e8cb73-23b3-4ba2-9c80-b926fccb34ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsaGM-QmNFwf",
        "outputId": "0c097a0d-b97d-494b-870d-7d9fa3e561de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80% data will be used for training the model and rest 20% of data will used for testing the model's accuracy.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "F97fFQhXNHt5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "\n",
        "    def __init__(self, k = 3):\n",
        "        \"\"\"\n",
        "        Initialize the KNN model with the specified number of neighbors i.e. k.\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Fiting the KNN model to the training data. It stores the data for future predictions.\n",
        "\n",
        "        Parameters:\n",
        "        - X_train: The training data.\n",
        "        - y_train: The labels for the training data.\n",
        "        \"\"\"\n",
        "\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "\n",
        "    def euclidean_distance(self, X_train, X_test_point):\n",
        "        \"\"\"\n",
        "        Compute the Euclidean distance between a test point and each point in the training data.\n",
        "\n",
        "        Parameters:\n",
        "        - X_train: The training data.\n",
        "        - X_test_point: A single test point.\n",
        "\n",
        "        Returns:\n",
        "        - A DataFrame containing the distances between the test point and each training point.\n",
        "        \"\"\"\n",
        "\n",
        "        distances = []  # List to store distances between the test point and each training point.\n",
        "\n",
        "        for train_point in X_train:\n",
        "\n",
        "            # Compute squared difference for each feature\n",
        "            curr_distance = sum((train_point[col] - X_test_point[col]) ** 2 for col in range(len(train_point)))\n",
        "\n",
        "            # Take the square root of the sum to get the Euclidean distance\n",
        "            distances.append(np.sqrt(curr_distance))\n",
        "\n",
        "        # Convert distances to a DataFrame for easier sorting later\n",
        "        return pd.DataFrame(data = distances, columns = [\"dist\"])\n",
        "\n",
        "\n",
        "    def nearest_neighbors(self, distances):\n",
        "        \"\"\"\n",
        "        Identify the k nearest neighbors based on distance.\n",
        "\n",
        "        Parameters:\n",
        "        - distances: A DataFrame containing distances from the test point to each training point.\n",
        "\n",
        "        Returns:\n",
        "        - A DataFrame containing the k nearest neighbors.\n",
        "        \"\"\"\n",
        "\n",
        "        # Sort distances in ascending order and pick the first k rows (smallest distances)\n",
        "        df_nearest = distances.sort_values(by = \"dist\", axis = 0).head(self.k)\n",
        "\n",
        "        return df_nearest\n",
        "\n",
        "\n",
        "    def voting(self, df_nearest, y_train):\n",
        "        \"\"\"\n",
        "        Perform majority voting among the k nearest neighbors to determine the predicted label.\n",
        "\n",
        "        Parameters:\n",
        "        - df_nearest: DataFrame containing the k nearest neighbors.\n",
        "        - y_train: The labels of the training data.\n",
        "\n",
        "        Returns:\n",
        "        - The predicted label (the label with the most votes).\n",
        "        \"\"\"\n",
        "\n",
        "        # Get the indices of the nearest neighbors and retrieve their labels from y_train\n",
        "        nearest_labels = y_train[df_nearest.index]\n",
        "\n",
        "        # Count the frequency of each label (majority voting)\n",
        "        vote_counts = {}\n",
        "        for label in nearest_labels:\n",
        "            vote_counts[label] = vote_counts.get(label, 0) + 1\n",
        "\n",
        "        # Return the label with the highest vote count\n",
        "        return max(vote_counts, key = vote_counts.get)\n",
        "\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Predict the labels for the test data using the KNN algorithm.\n",
        "\n",
        "        Parameters:\n",
        "        - X_test: The test dataset.\n",
        "\n",
        "        Returns:\n",
        "        - A list of predicted labels for each test point.\n",
        "        \"\"\"\n",
        "\n",
        "        y_pred = []  # List to store predicted labels for each test point.\n",
        "\n",
        "        # Iterate over each test point and make predictions\n",
        "        for X_test_point in X_test:\n",
        "\n",
        "            # Compute distances between this test point and all training points\n",
        "            distances = self.euclidean_distance(self.X_train, X_test_point)\n",
        "\n",
        "            # Find the nearest neighbors\n",
        "            df_nearest_point = self.nearest_neighbors(distances)\n",
        "\n",
        "            # Perform majority voting to get the predicted label\n",
        "            y_pred_point = self.voting(df_nearest_point, self.y_train)\n",
        "\n",
        "            # Append the predicted label to the list\n",
        "            y_pred.append(y_pred_point)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "    def calc_accuracy(self, y_pred, y_test):\n",
        "        \"\"\"\n",
        "        Calculate the accuracy of the model by comparing predicted labels to actual labels.\n",
        "\n",
        "        Parameters:\n",
        "        - y_pred: List of predicted labels.\n",
        "        - y_test: List of actual labels.\n",
        "\n",
        "        Returns:\n",
        "        - Accuracy of the model as a percentage.\n",
        "        \"\"\"\n",
        "\n",
        "        correct_predictions = np.sum(np.array(y_pred) == np.array(y_test))\n",
        "        total_predictions = len(y_test)\n",
        "        accuracy = (correct_predictions / total_predictions) * 100\n",
        "        return accuracy"
      ],
      "metadata": {
        "id": "d8akEt1uNJtb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNN(3)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "accuracy = knn.calc_accuracy(y_pred, y_test)\n",
        "\n",
        "print(f\"Accuracy of KNN Model is which implemented from scratch is {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgtIwfKlNMt1",
        "outputId": "832cf7c7-79bd-444c-9054-969ae0f75247"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of KNN Model is which implemented from scratch is 100.00%\n"
          ]
        }
      ]
    }
  ]
}